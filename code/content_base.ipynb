{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10219836,"sourceType":"datasetVersion","datasetId":6317660}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom scipy.sparse import hstack\nfrom sklearn.decomposition import TruncatedSVD\nfrom scipy.sparse import csr_matrix\nfrom sklearn.model_selection import GridSearchCV, train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport lightgbm as lgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:47.012197Z","iopub.execute_input":"2024-12-16T20:16:47.012589Z","iopub.status.idle":"2024-12-16T20:16:47.020271Z","shell.execute_reply.started":"2024-12-16T20:16:47.012560Z","shell.execute_reply":"2024-12-16T20:16:47.019021Z"},"editable":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":"FILM_PATH = '/kaggle/input/csvfiles/cleaned_data.csv'\n\nRESOURCE_PATH = '/kaggle/input/csvfiles/cleaned_data.csv'\nRATINGS_PATH = '/kaggle/input/csvfiles'\n\nrating_files = [f'ratings_part_{i}.txt' for i in range(1, 11)]\nratings_dataframes = []\nfor file in rating_files:\n    file_path = os.path.join(RATINGS_PATH, file)\n    try:\n        df = pd.read_csv(file_path, delimiter=',', header=None, names=['user_id','film_id', 'rating'])\n        ratings_dataframes.append(df)\n    except Exception as e:\n        print(f\"Error in read {file}: {e}\")\n\nratings_data = pd.concat(ratings_dataframes, ignore_index=True)\ndata = pd.read_csv(FILM_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:47.022513Z","iopub.execute_input":"2024-12-16T20:16:47.022992Z","iopub.status.idle":"2024-12-16T20:16:48.645924Z","shell.execute_reply.started":"2024-12-16T20:16:47.022941Z","shell.execute_reply":"2024-12-16T20:16:48.644778Z"},"editable":false},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(ratings_data.columns)\nprint(data.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:48.647487Z","iopub.execute_input":"2024-12-16T20:16:48.647867Z","iopub.status.idle":"2024-12-16T20:16:48.654949Z","shell.execute_reply.started":"2024-12-16T20:16:48.647819Z","shell.execute_reply":"2024-12-16T20:16:48.653672Z"},"editable":false},"outputs":[{"name":"stdout","text":"Index(['user_id', 'film_id', 'rating'], dtype='object')\nIndex(['fid', 'name', 'description', 'ratingCount', 'ratingValue',\n       'contentRating', 'genre', 'keywords', 'duration', 'datePublished',\n       'actor', 'director', 'image'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"columns_to_keep = ['fid', 'contentRating', \n                   'genre', 'keywords', 'duration', 'actor', 'director']\n\nfilm_data = data[columns_to_keep]\nprint(film_data.info())\nfilm_data.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:48.657137Z","iopub.execute_input":"2024-12-16T20:16:48.657600Z","iopub.status.idle":"2024-12-16T20:16:48.724783Z","shell.execute_reply.started":"2024-12-16T20:16:48.657564Z","shell.execute_reply":"2024-12-16T20:16:48.723617Z"},"editable":false},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9814 entries, 0 to 9813\nData columns (total 7 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   fid            9814 non-null   int64  \n 1   contentRating  9814 non-null   object \n 2   genre          9814 non-null   object \n 3   keywords       9814 non-null   object \n 4   duration       9814 non-null   float64\n 5   actor          9814 non-null   object \n 6   director       9814 non-null   object \ndtypes: float64(1), int64(1), object(5)\nmemory usage: 536.8+ KB\nNone\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       fid contentRating                    genre  \\\n0   468569            PG       Action,Crime,Drama   \n1  1375666            PG  Action,Adventure,Sci-Fi   \n\n                                            keywords  duration  \\\n0  psychopath,superhero,moral dilemma,clown,crimi...    9120.0   \n1  dream,ambiguous ending,subconscious,mindbender...    8880.0   \n\n                                               actor           director  \n0          Christian Bale,Heath Ledger,Aaron Eckhart  Christopher Nolan  \n1  Leonardo DiCaprio,Joseph Gordon-Levitt,Elliot ...  Christopher Nolan  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fid</th>\n      <th>contentRating</th>\n      <th>genre</th>\n      <th>keywords</th>\n      <th>duration</th>\n      <th>actor</th>\n      <th>director</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>468569</td>\n      <td>PG</td>\n      <td>Action,Crime,Drama</td>\n      <td>psychopath,superhero,moral dilemma,clown,crimi...</td>\n      <td>9120.0</td>\n      <td>Christian Bale,Heath Ledger,Aaron Eckhart</td>\n      <td>Christopher Nolan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1375666</td>\n      <td>PG</td>\n      <td>Action,Adventure,Sci-Fi</td>\n      <td>dream,ambiguous ending,subconscious,mindbender...</td>\n      <td>8880.0</td>\n      <td>Leonardo DiCaprio,Joseph Gordon-Levitt,Elliot ...</td>\n      <td>Christopher Nolan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Tính số lượng đánh giá của mỗi người dùng\nuser_rating_counts = ratings_data['user_id'].value_counts()\n\n# Chia người dùng thành các nhóm theo số lượng phim đã đánh giá\nusers_1_50 = user_rating_counts[(user_rating_counts >= 1) & (user_rating_counts <= 50)].index.to_numpy()\nusers_51_100 = user_rating_counts[(user_rating_counts >= 51) & (user_rating_counts <= 100)].index.to_numpy()\nusers_101_200 = user_rating_counts[(user_rating_counts >= 101) & (user_rating_counts <= 200)].index.to_numpy()\nusers_201_500 = user_rating_counts[(user_rating_counts >= 201) & (user_rating_counts <= 500)].index.to_numpy()\nusers_501_1000 = user_rating_counts[(user_rating_counts >= 501) & (user_rating_counts <= 1000)].index.to_numpy()\nusers_1001_2000 = user_rating_counts[(user_rating_counts >= 1001) & (user_rating_counts <= 2000)].index.to_numpy()\nusers_2001_12000 = user_rating_counts[(user_rating_counts >= 2001) & (user_rating_counts <= 12000)].index.to_numpy()\n\n# Train-test split cho từng nhóm\nusers_1_50_train, users_1_50_test = train_test_split(users_1_50, test_size=0.2, random_state=24)\nusers_51_100_train, users_51_100_test = train_test_split(users_51_100, test_size=0.2, random_state=24)\nusers_101_200_train, users_101_200_test = train_test_split(users_101_200, test_size=0.2, random_state=24)\nusers_201_500_train, users_201_500_test = train_test_split(users_201_500, test_size=0.2, random_state=24)\nusers_501_1000_train, users_501_1000_test = train_test_split(users_501_1000, test_size=0.2, random_state=24)\nusers_1001_2000_train, users_1001_2000_test = train_test_split(users_1001_2000, test_size=0.2, random_state=24)\nusers_2001_12000_train, users_2001_12000_test = train_test_split(users_2001_12000, test_size=0.2, random_state=24)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:48.726144Z","iopub.execute_input":"2024-12-16T20:16:48.726497Z","iopub.status.idle":"2024-12-16T20:16:48.840900Z","shell.execute_reply.started":"2024-12-16T20:16:48.726466Z","shell.execute_reply":"2024-12-16T20:16:48.839750Z"},"editable":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# tfidf_description = TfidfVectorizer(stop_words='english')\n# tfidf_genre = TfidfVectorizer(stop_words='english')\n# tfidf_keywords = TfidfVectorizer(stop_words='english')\n# tfidf_actor = TfidfVectorizer(stop_words='english')\n# tfidf_director = TfidfVectorizer(stop_words='english')\n\n# # Vectorizer\n# description_matrix = tfidf_description.fit_transform(film_data['description'])\n# genre_matrix = tfidf_genre.fit_transform(film_data['genre'])\n# keywords_matrix = tfidf_keywords.fit_transform(film_data['keywords'])\n# actor_matrix = tfidf_actor.fit_transform(film_data['actor'])\n# director_matrix = tfidf_director.fit_transform(film_data['director'])\n\n# # One hot encoder\n# onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n# contentRating_matrix = onehot_encoder.fit_transform(film_data[['contentRating']])\n\n# scaler = StandardScaler()\n# duration_matrix = scaler.fit_transform(film_data[['duration']])\n\n# items_combined = hstack([\n#     description_matrix, genre_matrix, keywords_matrix, \n#     actor_matrix, director_matrix, contentRating_matrix, duration_matrix\n# ])\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:48.842392Z","iopub.execute_input":"2024-12-16T20:16:48.842950Z","iopub.status.idle":"2024-12-16T20:16:48.852982Z","shell.execute_reply.started":"2024-12-16T20:16:48.842834Z","shell.execute_reply":"2024-12-16T20:16:48.851712Z"},"editable":false},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom scipy.sparse import hstack\n\nfilm_data['combined_text'] = film_data['genre'] + \" \" + film_data['keywords'] + \" \" + film_data['actor'] + \" \" + film_data['director']\n\ntfidf = TfidfVectorizer(stop_words='english')\ncombined_text_matrix = tfidf.fit_transform(film_data['combined_text'])\n\n# # One hot encoder cho contentRating\n# onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n# contentRating_matrix = onehot_encoder.fit_transform(film_data[['contentRating']])\n\n# scaler = StandardScaler()\n# duration_matrix = scaler.fit_transform(film_data[['duration']])\n\n# items_combined = hstack([\n#     combined_text_matrix, contentRating_matrix, duration_matrix\n# ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:48.854549Z","iopub.execute_input":"2024-12-16T20:16:48.854920Z","iopub.status.idle":"2024-12-16T20:16:49.166935Z","shell.execute_reply.started":"2024-12-16T20:16:48.854886Z","shell.execute_reply":"2024-12-16T20:16:49.165646Z"},"editable":false},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_24/4042218.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  film_data['combined_text'] = film_data['genre'] + \" \" + film_data['keywords'] + \" \" + film_data['actor'] + \" \" + film_data['director']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Normalize all columns\nscaler = StandardScaler(with_mean=False)\nitems_scaled = scaler.fit_transform(combined_text_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:49.168297Z","iopub.execute_input":"2024-12-16T20:16:49.168604Z","iopub.status.idle":"2024-12-16T20:16:49.182581Z","shell.execute_reply.started":"2024-12-16T20:16:49.168575Z","shell.execute_reply":"2024-12-16T20:16:49.181276Z"},"editable":false},"outputs":[],"execution_count":13},{"cell_type":"code","source":"items_sparse = csr_matrix(items_scaled)\n\nsvd = TruncatedSVD(n_components=8, random_state=42) \nitems_reduced = svd.fit_transform(items_sparse)\nprint(f\"Reduced items shape: {items_reduced.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:49.186696Z","iopub.execute_input":"2024-12-16T20:16:49.187069Z","iopub.status.idle":"2024-12-16T20:16:49.389756Z","shell.execute_reply.started":"2024-12-16T20:16:49.187036Z","shell.execute_reply":"2024-12-16T20:16:49.386911Z"},"editable":false},"outputs":[{"name":"stdout","text":"Reduced items shape: (9814, 8)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Data scaled for Ridge since it has a built-in svd solver\nitems_combined_dense = items_sparse.toarray()\ndata_scaled = pd.DataFrame(items_combined_dense).assign(fid=film_data['fid'])\ndata_reduced = pd.DataFrame(items_reduced).assign(fid=film_data['fid'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:49.391023Z","iopub.execute_input":"2024-12-16T20:16:49.391433Z","iopub.status.idle":"2024-12-16T20:16:55.151112Z","shell.execute_reply.started":"2024-12-16T20:16:49.391391Z","shell.execute_reply":"2024-12-16T20:16:55.150051Z"},"editable":false},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(f\"Reduced items shape: {data_reduced.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:55.152654Z","iopub.execute_input":"2024-12-16T20:16:55.153119Z","iopub.status.idle":"2024-12-16T20:16:55.159600Z","shell.execute_reply.started":"2024-12-16T20:16:55.153069Z","shell.execute_reply":"2024-12-16T20:16:55.158327Z"},"editable":false},"outputs":[{"name":"stdout","text":"Reduced items shape: (9814, 9)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Get feature_vector, real rating for each user\ndef get_items_rated_by_user(film_data, filt_ratings, user_id):\n    movie_ids = filt_ratings[filt_ratings['user_id'] == user_id]['film_id'].values\n    feature_vector = film_data[film_data['fid'].isin(movie_ids)].drop(columns='fid')\n    scores = filt_ratings[filt_ratings['user_id'] == user_id]['rating'].values\n    return feature_vector, scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:55.160982Z","iopub.execute_input":"2024-12-16T20:16:55.161366Z","iopub.status.idle":"2024-12-16T20:16:55.176452Z","shell.execute_reply.started":"2024-12-16T20:16:55.161331Z","shell.execute_reply":"2024-12-16T20:16:55.175056Z"},"editable":false},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def predict_known_ratings_for_user(film_data, user_id, model):\n    X, y = get_items_rated_by_user(film_data, ratings_data, user_id)\n    model.fit(X, y)\n    return np.clip(model.predict(X), 1, 10)\ndef get_not_seen_movies_from_user(film_data, user_id):\n    user_ratings = ratings_data[ratings_data['user_id'] == user_id]\n    seen_movies = film_data['fid'].isin(user_ratings['fid'])\n    return film_data[~seen_movies].drop(columns='fid')\ndef predict_unknown_ratings_for_user(film_data, user_id, model):\n    X, y = get_items_rated_by_user(film_data, ratings_data, user_id)\n    X_test = get_not_seen_movies_from_user(user_id)\n    model.fit(X, y)\n    return np.clip(model.predict(X_test), 0.5, 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:55.177909Z","iopub.execute_input":"2024-12-16T20:16:55.178371Z","iopub.status.idle":"2024-12-16T20:16:55.191035Z","shell.execute_reply.started":"2024-12-16T20:16:55.178320Z","shell.execute_reply":"2024-12-16T20:16:55.189743Z"},"editable":false},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# demo of hyperparameters for tuning\nridge_param_grid = {\n#   'alpha': [40, 50, 60, 70, 80, 90],\n    'alpha': [40],\n}\n\nknn_param_grid = {\n  'n_neighbors': [30],\n}\n\n\nrf_param_grid = {\n  'n_estimators': [300],\n}\nlgbm_param_grid = {\n    'num_leaves': [2],\n    'min_data_in_leaf': [10],\n    'boosting_type': ['gbdt']\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:55.192643Z","iopub.execute_input":"2024-12-16T20:16:55.193028Z","iopub.status.idle":"2024-12-16T20:16:55.208331Z","shell.execute_reply.started":"2024-12-16T20:16:55.192990Z","shell.execute_reply":"2024-12-16T20:16:55.206926Z"},"editable":false},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from tqdm import tqdm\ndef customized_grid_search(users, estimator, param_grid, param_grid_size, film_data):\n    final_rmse = np.zeros(param_grid_size)\n    final_mae = np.zeros(param_grid_size)\n    grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid,\n                                scoring=('neg_mean_squared_error', 'neg_mean_absolute_error'), refit=False,\n                                cv=KFold(3, shuffle=True), n_jobs=-1)\n    \n    for user in tqdm(users, desc=\"Processing users\", unit=\"user\"):\n        X, y = get_items_rated_by_user(film_data, ratings_data, user)\n        grid_search.fit(X, y)\n        mse = grid_search.cv_results_['mean_test_neg_mean_squared_error']\n        rmse = np.sqrt(-mse)\n        mae = grid_search.cv_results_['mean_test_neg_mean_absolute_error']\n        final_rmse += rmse\n        final_mae += mae\n    param_df = pd.DataFrame(grid_search.cv_results_['params'])\n    param_df['rmse'] = final_rmse / len(users)\n    param_df['mae'] = final_mae / len(users)\n    return param_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:55.210364Z","iopub.execute_input":"2024-12-16T20:16:55.210719Z","iopub.status.idle":"2024-12-16T20:16:55.230063Z","shell.execute_reply.started":"2024-12-16T20:16:55.210685Z","shell.execute_reply":"2024-12-16T20:16:55.228621Z"},"editable":false},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# demo of a parameter dataframe for tuning\nparam_df = customized_grid_search(users_1001_2000_train, Ridge(), ridge_param_grid, 2, data_scaled)\nparam_df.to_csv('/kaggle/working/ridge_1001_2000_param.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T20:16:55.231386Z","iopub.execute_input":"2024-12-16T20:16:55.231742Z"},"editable":false},"outputs":[{"name":"stderr","text":"Processing users:   1%|          | 7/785 [00:23<41:45,  3.22s/user]  ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n# get mean rmse and mae of a model on a dataset\ndef evaluate_model(model, users, film_data):\n    final_rmse = 0\n    final_mae = 0\n    for user in users:\n        X, y = get_items_rated_by_user(film_data, ratings_data, user)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        final_rmse += root_mean_squared_error(y_test, y_pred)\n        final_mae += mean_absolute_error(y_test, y_pred)\n    return final_rmse/len(users), final_mae/len(users)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# demo of evaluating model after finding optimal hyperparameter\ntrain_rmse, train_mae = evaluate_model(RandomForestRegressor(max_depth=20, n_jobs=-1),users_101_200_train, data_reduced)\nprint(\"done training\")\ntest_rmse, test_mae = evaluate_model(RandomForestRegressor(max_depth=20, n_jobs=-1) ,users_101_200_test, data_reduced)\nprint(f'Train MAE: {train_mae}')\nprint(f'Train RMSE: {train_rmse}')\nprint(f'Test MAE: {test_mae}')\nprint(f'Test RMSE: {test_rmse}')","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}
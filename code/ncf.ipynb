{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir, path, getcwd\n",
    "for i in range(10):\n",
    "    if path.isfile('checkcwd'):\n",
    "        break\n",
    "    chdir(path.pardir)\n",
    "if path.isfile('checkcwd'):\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('Something went wrong. cwd=' + getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "import wandb\n",
    "import datetime\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_DIR = 'resources/data/train_val_test'\n",
    "CHECKPOINT_PATH = 'resources/checkpoints'\n",
    "\n",
    "batch_size = 512\n",
    "layers = [64, 32, 16]\n",
    "reg_layers = [0.25, 0.25, 0.25]\n",
    "learning_rate = 5e-4\n",
    "epochs = 50\n",
    "\n",
    "k = 20\n",
    "threshold = 7\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{RATINGS_DIR}/ratings_train.csv', header=None, dtype='int32')\n",
    "df_train.columns = ['uid', 'fid', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(f'{RATINGS_DIR}/ratings_val.csv', header=None, dtype='int32')\n",
    "df_val.columns = ['uid', 'fid', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_train, df_val], ignore_index=True) # no effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        users = self.users[item]\n",
    "        movies = self.movies[item]\n",
    "        ratings = self.ratings[item]\n",
    "\n",
    "        return {\n",
    "            'uid': torch.tensor(users, dtype=torch.int),\n",
    "            'fid': torch.tensor(movies, dtype=torch.int),\n",
    "            'rating': torch.tensor(ratings, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc_uid = preprocessing.LabelEncoder()\n",
    "label_enc_fid = preprocessing.LabelEncoder()\n",
    "\n",
    "df_train.uid = label_enc_uid.fit_transform(df_train.uid.values)\n",
    "df_train.fid = label_enc_fid.fit_transform(df_train.fid.values)\n",
    "\n",
    "df_val.uid = label_enc_uid.transform(df_val.uid.values)\n",
    "df_val.fid = label_enc_fid.transform(df_val.fid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\n",
    "    list(df_train.uid),\n",
    "    list(df_train.fid),\n",
    "    list(df_train.rating)\n",
    ")\n",
    "\n",
    "val_dataset = MyDataset(\n",
    "    list(df_val.uid),\n",
    "    list(df_val.fid),\n",
    "    list(df_val.rating)\n",
    ")\n",
    "\n",
    "# r = 3\n",
    "\n",
    "# train_dataset = MyDataset(\n",
    "#     list(df_train.uid)[::r],\n",
    "#     list(df_train.fid)[::r],\n",
    "#     list(df_train.rating)[::r]\n",
    "# )\n",
    "\n",
    "# val_dataset = MyDataset(\n",
    "#     list(df_val.uid)[::r],\n",
    "#     list(df_val.fid)[::r],\n",
    "#     list(df_val.rating)[::r]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, layers, reg_layers):\n",
    "        super(RecSysModel, self).__init__()\n",
    "        self.num_layers = len(layers)\n",
    "\n",
    "        # split for concat later\n",
    "        self.user_embedding = nn.Embedding(num_users, layers[0] // 2)\n",
    "        self.item_embedding = nn.Embedding(num_items, layers[0] // 2)\n",
    "\n",
    "        fc_layers = []\n",
    "        input_size = layers[0]\n",
    "        for i in range(1, len(layers)):\n",
    "            fc_layers.append(nn.Linear(input_size, layers[i]))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            if reg_layers[i] > 0:\n",
    "                fc_layers.append(nn.Dropout(reg_layers[i]))\n",
    "            input_size = layers[i]\n",
    "\n",
    "        self.fc_layers = nn.Sequential(*fc_layers)\n",
    "        self.output_layer = nn.Linear(layers[-1], 1)\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        # [batch, num_users, embed_size]\n",
    "        user_latent = self.user_embedding(user_input)\n",
    "        item_latent = self.item_embedding(item_input)\n",
    "\n",
    "        vector = torch.cat([user_latent, item_latent], dim=-1)\n",
    "\n",
    "        vector = self.fc_layers(vector)\n",
    "\n",
    "        prediction = self.output_layer(vector)\n",
    "        return prediction\n",
    "\n",
    "    def _init_weight(self):\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(user_ratings, k, threshold):\n",
    "    user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    n_rel = sum(true_r >= threshold for _, true_r in user_ratings)\n",
    "    n_rec_k = sum(est >= threshold for est, _ in user_ratings[:k])\n",
    "    n_rel_and_rec_k = sum(\n",
    "        (true_r >= threshold) and (est >= threshold) for est, true_r in user_ratings[:k]\n",
    "    )\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecSysModel(\n",
    "    num_users=len(label_enc_uid.classes_),\n",
    "    num_items=len(label_enc_fid.classes_),\n",
    "    layers=layers,\n",
    "    reg_layers=reg_layers\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "\n",
    "RESUME = 'allow'\n",
    "wandb.init(\n",
    "    project='RecSysNCF',\n",
    "    resume=RESUME,\n",
    "    name=str(datetime.datetime.now()),\n",
    "    config={\n",
    "        'batch_size': batch_size,\n",
    "        'layers': layers,\n",
    "        'reg_layers': reg_layers,\n",
    "        'learning_rate': learning_rate,\n",
    "        'epochs': epochs\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.watch(model)\n",
    "best_f1_score = float('-inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    print(f'\\nEpoch [{epoch+1}/{epochs}]')\n",
    "\n",
    "    for i, train_data in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        uid = train_data['uid'].to(device)\n",
    "        fid = train_data['fid'].to(device)\n",
    "        rating = train_data[\"rating\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output: torch.Tensor = model(\n",
    "            uid, fid\n",
    "        )\n",
    "        # [batch, 1] -> [batch]\n",
    "        output = output.squeeze()\n",
    "\n",
    "        loss = loss_func(output, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Average Training Loss for Epoch {epoch+1}: {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()  \n",
    "    total_val_loss = 0\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    user_ratings_comparison = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, val_data in enumerate(tqdm(val_loader)):\n",
    "            uid = val_data['uid'].to(device)\n",
    "            fid = val_data['fid'].to(device)\n",
    "            rating = val_data[\"rating\"].to(device)\n",
    "\n",
    "            output = model(\n",
    "                uid, fid\n",
    "            )\n",
    "            output = output.squeeze()\n",
    "\n",
    "            loss = loss_func(output, rating)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            y_pred.extend(output.cpu().numpy())\n",
    "            y_true.extend(rating.cpu().numpy())\n",
    "            for user, pred, true in zip(uid, output, rating):\n",
    "                user_ratings_comparison[user.item()].append((pred.item(), true.item()))\n",
    "\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    avg_precision = 0.0\n",
    "    avg_recall = 0.0\n",
    "\n",
    "    for user, user_ratings in user_ratings_comparison.items():\n",
    "        precision, recall = calculate_precision_recall(user_ratings, k, threshold)\n",
    "        avg_precision += precision\n",
    "        avg_recall += recall\n",
    "    \n",
    "    avg_precision /= len(user_ratings_comparison)\n",
    "    avg_recall /= len(user_ratings_comparison)\n",
    "    f1_score = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    print(f'val_loss: {avg_val_loss:.4f}, rmse: {rmse:.4f}, precision: {avg_precision:.4f}, recall: {avg_recall:.4f}, f1:{f1_score:.4f}')\n",
    "\n",
    "\n",
    "    if f1_score > best_f1_score:\n",
    "        best_f1_score = f1_score\n",
    "        torch.save(model.state_dict(), f'{CHECKPOINT_PATH}/ncf.pth')\n",
    "        print(f\"f1-score improved. Model checkpoint saved at epoch {epoch+1}.\")\n",
    "    else:\n",
    "        print(\"f1-score did not improve.\")\n",
    "\n",
    "    wandb.log({\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'rmse': rmse,\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1': f1_score\n",
    "    })\n",
    "\n",
    "    print('-' * 50)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thanh309-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
